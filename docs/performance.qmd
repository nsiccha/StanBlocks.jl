---
title: "Julia vs Stan performance comparison"
---

# Caveats

This page compares the performance of Julia's and Stan's log density and log density gradient computations for the implemented posteriors. Several caveats apply:

* The `posteriordb` Stan implementations were never meant to represent "perfect and best-performant" practices.
* The StanBlocks.jl implementations are not line-by-line translations of the Stan implementations. Sometimes small optimizations were applied, to make the implementation fall more in line with common Julia practices, or to make the code more friendly for Julia's AD packages, e.g. by avoiding mutation.
* Stan often automatically drops constant terms (unless configured differently), see [https://mc-stan.org/docs/reference-manual/statements.html#log-probability-increment-vs.-distribution-statement](https://mc-stan.org/docs/reference-manual/statements.html#log-probability-increment-vs.-distribution-statement), thus avoiding superfluous (for its purposes) computation, while the StanBlocks.jl implementations do not.
* Stan implements a lot of custom AD rules, while StanBlocks.jl does not at all, and Enzyme.jl does rarely (if ever?). I suspect that adding AD rules for `_glm_` type functions would further improve Julia's performance.
* The StanBlocks.jl "sampling" statements try to be clever about avoiding repeated computations. While I am not sure whether Stan applies the same optimizations, in principle it could do that without extra work by the user. 
* While preliminary benchmark runs included "all" Julia AD packages, all of them are almost always much slower than Enzyme.jl for the implemented posteriors, which on top of that performance advantage also supports more Julia language features than some of the other AD packages. As such, I am only comparing Enzyme and Stan. Enzyme outperforming every other AD package for *these* posteriors/loss functions does of course not mean that it will necessarily do as well for other applications.
* Enzyme's development is progressing quite quickly. While it currently sometimes crashes Julia, or it sometimes errors while trying to compute a gradient, in general Enzyme's performance and reliability are continuously and quickly improving.
* Stan's benchmark is done from Julia via `BridgeStan.jl`. While I think that any performance penalty should be extremely small, I am not 100% sure. BridgeStan uses the `-O3` compiler flag by default, but no additional ones.
* All benchmarks are happening with a single thread on my local machine.
* **There are probably more caveats!**

::: {.callout-warning}
**In general, doing performance comparisons is quite tricky, for more reasons than just the ones mentioned above. The below plot and tables should most definitely NOT be interpreted as "A is X-times faster than B".**
::: 
```{julia}
using Random, Chairmarks, Statistics, LinearAlgebra, Distributions, Plots
import Plots, OnlineStats, StanBlocks
include("julia/common.jl")
struct RuntimeDistribution2{F}
    f::F
    n::Int64
end
RuntimeDistribution2(f) = RuntimeDistribution2(f, 1)
RuntimeDistribution2(f::RuntimeDistribution2, n::Int64) = RuntimeDistribution2(f.f, n * f.n)
@inline Random.rand(rng::AbstractRNG, d::RuntimeDistribution2) = begin
    stats = @timed begin
        rv = d.f(rng)
        Base.donotdelete(rv)
        for i in 1:d.n-1
            rv = max(rv, d.f(rng))
            Base.donotdelete(rv)
        end
    end
    (stats.time - stats.gctime) / d.n
end

struct IterableDistribution{R,D}
    rng::R
    dist::D
end
@inline Base.iterate(d::IterableDistribution) = rand(d.rng, d.dist)
struct UncertainMean{V,Q}
    var::V
    qmul::Q
end
round2(x) = round(x; sigdigits=2)
Base.show(io::IO, s::UncertainMean) = print(io, "[", round2(lower(s)), " -- ", round2(upper(s)), "] (via ", OnlineStats.nobs(s), " evaluations)")
Base.show(io::IO, ::MIME"text/plain", s::UncertainMean) = show(io, s)
UncertainMean(q::Real) = UncertainMean(OnlineStats.Variance(), quantile(Normal(), 1-q))
OnlineStats.fit!(s::UncertainMean, args...) = OnlineStats.fit!(s.var, args...)
OnlineStats.nobs(s::UncertainMean) = OnlineStats.nobs(s.var)
se(s::UncertainMean) = sqrt(var(s.var)/OnlineStats.nobs(s.var))
Statistics.mean(s::UncertainMean) = mean(s.var)
upper(s::UncertainMean) = mean(s) + atol(s)
lower(s::UncertainMean) = mean(s) - atol(s)
atol(s::UncertainMean) = s.qmul * se(s)
rtol(s::UncertainMean) = atol(s) / abs(mean(s))
Base.:isless(s1::UncertainMean, s2::UncertainMean) = upper(s1) < lower(s2) ? true : false#(upper(s2) < lower(s1) ? false : missing)
adaptive_mean3(args...; q, kwargs...) = adaptive_mean3(args, [UncertainMean(q) for arg in args]; kwargs...)
adaptive_mean3(args::Tuple, means::Vector; n_min=10, n_max=1_000_000, rtol=.01) = begin
    N = length(args)
    vmeans = map(mean, means)
    perm = sortperm(vmeans)
    draws = map(iterate, args)
    n_start = 1+minimum(OnlineStats.nobs, means)
    n_start > 1 && display("Resuming at $n_start")
    for i in n_start:n_max
        draws = map(iterate, args)
        for (m, d) in zip(means, draws)
            OnlineStats.fit!(m, d)
        end
        i < n_min && continue
        map!(mean, vmeans, means)
        sortperm!(perm, vmeans)
        is_sorted = all(i->means[perm[i-1]] < means[perm[i]], 2:N)
        is_precise = all(m->Main.rtol(m) < rtol, means)
        if is_sorted && is_precise
            display("Stopping early at i=$i")
            break
        end
    end
    means
end
firstfinite(f) = ff(args...) = while true
    rv = f(args...)
    isfinite(rv) && return rv
end
nonzero(x) = x == zero(x) ? one(x) : x
adaptive_median(f::Function; n_min=100, n_max=1000, rtol=.001, q=.5) = begin 
    ff = firstfinite(f)
    vals = [ff()]
    w = [1.]
    qs = [0.]
    rv = vals[1]
    for i in 2:n_max
        val = ff()
        insert!(vals, searchsortedfirst(vals, val), val)
        # @assert issorted(vals)
        rv = quantile(vals, q; sorted=true)
        push!(w, 0.)
        push!(qs, 0.)
        rand!(w)
        @. w = -log1p(-w)
        cumsum!(qs, w)
        qm = q * qs[end]
        ridx = searchsortedfirst(qs, qm)
        rep = if ridx == 1
            vals[1]
        else
            lidx = ridx-1
            wl = (qm - qs[lidx]) / (qs[ridx] - qs[lidx])
            wr = 1 - wl
            wl * vals[lidx] + wr * vals[ridx]
        end
        rel_err = norm((rv - rep)/nonzero(max(norm(rv),norm(rep))))
        i < n_min && continue
        # Stopping criterion should be more sophisticated
        if rel_err < rtol
            display((;vals, rv, rep, rel_err))
            display("Stopping early at i=$i")
            break
        end 
    end
    rv
end

skip_names = split("""
uk_drivers-state_space_stochastic_level_stochastic_seasonal
timssAusTwn_irt-gpcm_latent_reg_irt
synthetic_grid_RBF_kernels-kronecker_gp
state_wide_presidential_votes-hierarchical_gp	
soil_carbon-soil_incubation	
sir-sir	
sat-hier_2pl	
rstan_downloads-prophet	
one_comp_mm_elim_abs-one_comp_mm_elim_abs	
mnist_100-nn_rbm1bJ10	
mnist-nn_rbm1bJ100	
iohmm_reg_simulated-iohmm_reg	
hudson_lynx_hare-lotka_volterra	
fims_Aus_Jpn_irt-2pl_latent_reg_irt
ecdc0501-covid19imperial_v3		
ecdc0501-covid19imperial_v2	
ecdc0401-covid19imperial_v3	
ecdc0401-covid19imperial_v2	
dogs-dogs_nonhierarchical	
butterfly-multi_occupancy	
""")
jdf = map(posterior_names) do posterior_name
    posterior_name in skip_names && return (;posterior_name)
    try
        e = PosteriorEvaluation(posterior_name)
        e.df_row
    catch e
        isa(e, InterruptException) && rethrow()
        @error posterior_name e
        rethrow()
        return (;posterior_name)
    end
end |> filter(!isnothing) |> pad_missing |> DataFrame;
```
:::{.column-page}
 
# Visualization

::: {.callout-warning}
**In general, doing performance comparisons is quite tricky, for more reasons than just the ones mentioned above. The below plot and tables should most definitely NOT be interpreted as "A is X-times faster than B".**
:::

The below plot shows the relative primitive runtime (x-axis, Julia vs Stan, left: Julia is faster) and the relative gradient runtime (y-axis, Julia+X vs Stan, bottom: Julia is faster) for the `posteriordb` models for which the [overview table](#tabular-data) has a value less than `1e-8` in the `median relative ulpdf error` column. **The color of the points represents the Julia AD framework used**, which currently includes [Enzyme.jl](https://github.com/EnzymeAD/Enzyme.jl) and [Mooncake.jl](https://github.com/compintell/Mooncake.jl).
Hovering over the data points will show the posterior name, its dimension, the allocations required by Julia during the primitive and gradient run and a short explanation, e.g. `mesquite-logmesquite_logvash (D=7, #allocs=0->70) - Julia's primitive is ~4.5 times faster, but Enzyme's gradient is ~16.0 times slower.` **Any time spent on garbage collection has been subtracted from the measured wall times. All mean runtime estimates were run until the estimated standard error of the mean was smaller than roughly .5% of the estimated mean. Due to this, I have removed the credible intervals and standard errors from the plot and table.**
```{julia}
hover_string(posterior_name, dimension, ptime, gtime, pallocs, gallocs; AD) = begin  
    pdescr = if ptime > 1
        "$(round(ptime; sigdigits=2)) times slower" 
    else
        "$(round(inv(ptime); sigdigits=2)) times faster"
    end
    gdescr = if gtime > 1
        "$(round(gtime; sigdigits=2)) times slower"
    else
        "$(round(inv(gtime); sigdigits=2)) times faster"
    end
    jdescr = if (ptime > 1) == (gtime > 1) 
        "and"
    else
        "but"
    end
    descr = "Julia's primitive is ~$pdescr, $jdescr $AD's gradient is ~$gdescr."
    "$(posterior_name) (D=$(dimension), #allocs=$(round(pallocs))->$(round(gallocs))) <br> $descr"
end
pdf = jdf = DataFrame(filter(row->!ismissing(row.stan_gradient_times), eachrow(jdf)))
pdf.ptime = mean.(pdf.julia_lpdf_times) ./ mean.(pdf.stan_lpdf_times)
pdf.etime = mean.(pdf.enzyme_times) ./ mean.(pdf.stan_gradient_times) 
pdf.mtime = mean.(pdf.mooncake_times) ./ mean.(pdf.stan_gradient_times)

colors = palette(:tab10)[[1,2]]
Plots.vline!(
Plots.hline!(
    Plots.scatter(
        pdf.ptime,
        [pdf.etime, pdf.mtime];
        label=["Enzyme" "Mooncake"],
        color=permutedims(colors),
        hover=hcat(
            hover_string.(pdf.posterior_name, pdf.dimension, pdf.ptime, pdf.etime, pdf.julia_allocations, pdf.enzyme_allocations; AD="Enzyme"), 
            hover_string.(pdf.posterior_name, pdf.dimension, pdf.ptime, pdf.mtime, pdf.julia_allocations, pdf.mooncake_allocations; AD="Mooncake") 
        ),
        xlabel="Relative primitive runtime\n(Julia vs Stan, left: Julia is faster)", 
        ylabel="Relative gradient runtime\n(Julia+X vs Stan, bottom: Julia+X is faster)",
        title="Relative mean runtimes, EXCLUDING GARBAGE COLLECTION",
        xscale=:log10, yscale=:log10, 
        size=(1000, 600)
    ),
    [1], color=:black, label="", hover=""
),
    [1], color=:black, label="", hover=""
)
```
:::

# Tabular data

The below table shows information about the implemented posteriors. Will elaborate on the exact meaning of columns.

:::{.column-screen}

```{julia}
ternary(c, t, f) = c ? t : f 
hl_best = HtmlHighlighter(
    (data, i, j) -> data[i,j] === 1.,
    HtmlDecoration(color="blue", font_weight="bold")
);
hl_failed = HtmlHighlighter(
    (data, i, j) -> ((data[i,j]==="FAILED")),
    HtmlDecoration(color = "red")
);
relative!(args...) = begin
    for i in eachindex(args[1])
        setindex!.(args, getindex.(args, i) ./ minimum(getindex.(args, i)), i)
    end
    args
end
julia_lpdf_times, stan_lpdf_times = relative!(mean.(jdf.julia_lpdf_times), mean.(jdf.stan_lpdf_times))
enzyme_times, mooncake_times, stan_gradient_times = relative!(mean.(jdf.enzyme_times), mean.(jdf.mooncake_times), mean.(jdf.stan_gradient_times))
pretty_table( 
    DataFrame(OrderedDict(  
        "posterior name"=>jdf.posterior_name,
        "dimension"=>jdf.dimension,
        "median relative ulpdf error"=>round2.(jdf.lpdf_accuracy),
        "relative mean primitive Julia runtime"=>round2.(julia_lpdf_times),
        "relative mean primitive Stan runtime"=>round2.(stan_lpdf_times),
        "relative mean Enzyme runtime"=>round2.(enzyme_times),
        "relative mean Mooncake runtime"=>round2.(mooncake_times),
        "relative mean Stan gradient runtime"=>round2.(stan_gradient_times),
        "primitive Julia allocations"=>jdf.julia_allocations,
        "Enzyme allocations"=>jdf.enzyme_allocations,
        "Mooncake allocations"=>jdf.mooncake_allocations,
        "median lpdf difference"=>round2.(jdf.lpdf_difference),
        "median Enzyme relative gradient error"=>round2.(jdf.enzyme_accuracy),
        "median Mooncake relative gradient error"=>round2.(jdf.mooncake_accuracy), 
        "Bridgestan"=>jdf.BRIDGESTAN_VERSION,
        "Enzyme"=>jdf.ENZYME_VERSION,
        "Mooncake"=>jdf.MOONCAKE_VERSION,
        "implementations"=>implementations_string.(jdf.posterior_name)
    ));
    backend=Val(:html),
    highlighters=(hl_best, hl_failed,), 
    show_subheader=false, 
    table_class="interactive"
)
```
:::