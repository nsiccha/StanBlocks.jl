---
title: "Julia vs Stan performance comparison"
---

# Caveats

This page compares the performance of Julia's and Stan's log density and log density gradient computations for the implemented posteriors. Several caveats apply:

* The `posteriordb` Stan implementations were never meant to represent "perfect and best-performant" practices.
* The StanBlocks.jl implementations are not line-by-line translations of the Stan implementations. Sometimes small optimizations were applied, to make the implementation fall more in line with common Julia practices, or to make the code more friendly for Julia's AD packages, e.g. by avoiding mutation.
* Stan often automatically drops constant terms (unless configured differently), see [https://mc-stan.org/docs/reference-manual/statements.html#log-probability-increment-vs.-distribution-statement](https://mc-stan.org/docs/reference-manual/statements.html#log-probability-increment-vs.-distribution-statement), thus avoiding superfluous (for its purposes) computation, while the StanBlocks.jl implementations do not.
* Stan implements a lot of custom AD rules, while StanBlocks.jl does not at all, and Enzyme.jl does rarely (if ever?). I suspect that adding AD rules for `_glm_` type functions would further improve Julia's performance.
* The StanBlocks.jl "sampling" statements try to be clever about avoiding repeated computations. While I am not sure whether Stan applies the same optimizations, in principle it could do that without extra work by the user. 
* While preliminary benchmark runs included "all" Julia AD packages, all of them are almost always much slower than Enzyme.jl for the implemented posteriors, which on top of that performance advantage also supports more Julia language features than some of the other AD packages. As such, I am only comparing Enzyme and Stan. Enzyme outperforming every other AD package for *these* posteriors/loss functions does of course not mean that it will necessarily do as well for other applications.
* Enzyme's development is progressing quite quickly. While it currently sometimes crashes Julia, or it sometimes errors while trying to compute a gradient, in general Enzyme's performance and reliability are continuously and quickly improving.
* Stan's benchmark is done from Julia via `BridgeStan.jl`. While I think that any performance penalty should be extremely small, I am not 100% sure. BridgeStan uses the `-O3` compiler flag by default, but no additional ones.
* All benchmarks are happening with a single thread on my local machine.
* **There are probably more caveats!**

::: {.callout-warning}
**In general, doing performance comparisons is quite tricky, for more reasons than just the ones mentioned above. The below plot and tables should most definitely NOT be interpreted as "A is X-times faster than B".**
::: 

```{julia}
include("julia/common.jl")
jdf = map(posterior_names) do posterior_name 
    PosteriorEvaluation(posterior_name).df_row   
end |> pad_missing |> DataFrame; 
```

:::{.column-page}
 
# Visualization

::: {.callout-warning}
**In general, doing performance comparisons is quite tricky, for more reasons than just the ones mentioned above. The below plot and tables should most definitely NOT be interpreted as "A is X-times faster than B".**
:::

The below plot shows the relative primitive runtime (x-axis, Julia vs Stan, left: Julia is faster) and the relative gradient runtime (y-axis, Julia+X vs Stan, bottom: Julia is faster) for the `posteriordb` models for which the [overview table](#tabular-data) has a value less than `1e-8` in the `remaining relative lpdf error` column. **The color of the points represents the Julia AD framework used**, which currently includes [Enzyme.jl](https://github.com/EnzymeAD/Enzyme.jl) and [Mooncake.jl](https://github.com/compintell/Mooncake.jl).
Hovering over the data points will show the posterior name, its dimension, the allocations required by Julia during the primitive and gradient run and a short explanation, e.g. `mesquite-logmesquite_logvash (D=7, #allocs=0->70) - Julia's primitive is ~4.5 times faster, but Enzyme's gradient is ~16.0 times slower.` Horizontal and vertical lines around scatter points represent the 90% central credible interval of the ratio of the runtime means, estimated using 200 iterations of Bayesian Bootstrap. **As those intervals are sometimes quite wide, I'm planning to rerun some or all of the benchmarks.**
```{julia}
hover_string(posterior_name, dimension, ptime, gtime, pallocs, gallocs; AD) = begin  
    pdescr = if ptime > 1
        "$(round(ptime; sigdigits=2)) times slower" 
    else
        "$(round(inv(ptime); sigdigits=2)) times faster"
    end
    gdescr = if gtime > 1
        "$(round(gtime; sigdigits=2)) times slower"
    else
        "$(round(inv(gtime); sigdigits=2)) times faster"
    end
    jdescr = if (ptime > 1) == (gtime > 1) 
        "and"
    else
        "but"
    end
    descr = "Julia's primitive is ~$pdescr, $jdescr $AD's gradient is ~$gdescr."
    "$(posterior_name) (D=$(dimension), #allocs=$(Int(pallocs))->$(Int(gallocs))) <br> $descr"
end
pdf = DataFrame(filter(row->!ismissing(row.stan_gradient_times), eachrow(jdf)))
pdf.ptime = val.(pdf.julia_lpdf_times) ./ val.(pdf.stan_lpdf_times)
pdf.etime = val.(pdf.enzyme_times) ./ val.(pdf.stan_gradient_times) 
pdf.mtime = val.(pdf.mooncake_times) ./ val.(pdf.stan_gradient_times)
ptime_ci = mapreduce(hcat, pdf.julia_lpdf_times, pdf.stan_lpdf_times) do j, s
    collect(ci(UncertainStatistic(ratio_of_means, (j.vals, s.vals))))
end
etime_ci = mapreduce(hcat, pdf.enzyme_times, pdf.stan_gradient_times) do j, s
    collect(ci(UncertainStatistic(ratio_of_means, (j.vals, s.vals))))
end
mtime_ci = mapreduce(hcat, pdf.mooncake_times, pdf.stan_gradient_times) do j, s
    collect(ci(UncertainStatistic(ratio_of_means, (j.vals, s.vals))))
end

colors = palette(:tab10)[[1,2]]
Plots.vline!(
Plots.hline!(
    Plots.scatter!(
        Plots.plot(
            [
                [pdf.ptime pdf.ptime]
                ptime_ci'
                [pdf.ptime pdf.ptime]
                ptime_ci'
            ]',
            [
                etime_ci'
                [pdf.etime pdf.etime]
                mtime_ci'
                [pdf.mtime pdf.mtime]
            ]',
            color=permutedims(vcat(fill(colors[1], 2*length(pdf.ptime)), fill(colors[2], 2*length(pdf.ptime)))), label="", hover=""
        ),
        pdf.ptime,
        [pdf.etime, pdf.mtime];
        label=["Enzyme" "Mooncake"],
        color=permutedims(colors),
        hover=hcat(
            hover_string.(pdf.posterior_name, pdf.dimension, pdf.ptime, pdf.etime, pdf.julia_lpdf_allocs, pdf.enzyme_allocs; AD="Enzyme"), hover_string.(pdf.posterior_name, pdf.dimension, pdf.ptime, pdf.mtime, pdf.julia_lpdf_allocs, pdf.mooncake_allocs; AD="Mooncake") 
        ),
        xlabel="Relative primitive runtime\n(Julia vs Stan, left: Julia is faster)", 
        ylabel="Relative gradient runtime\n(Julia+X vs Stan, bottom: Julia+X is faster)",
        xscale=:log10, yscale=:log10, 
        size=(1000, 600)
    ),
    [1], color=:black, label="", hover=""
),
    [1], color=:black, label="", hover=""
)
```
:::

# Tabular data

The below table shows information about the implemented posteriors. Will elaborate on the exact meaning of columns.

:::{.column-screen}

```{julia}
ternary(c, t, f) = c ? t : f 
pretty_table( 
    DataFrame(OrderedDict(  
        "posterior name"=>jdf.posterior_name,
        "dimension"=>jdf.dimension,
        "relative mean primitive Julia runtime"=>jdf.julia_lpdf_times,
        "relative mean primitive Stan runtime"=>jdf.stan_lpdf_times,
        "relative mean Enzyme runtime"=>jdf.enzyme_times,
        "relative mean Mooncake runtime"=>jdf.mooncake_times,
        "relative mean Stan gradient runtime"=>jdf.stan_gradient_times,
        "mean primitive Julia allocations"=>jdf.julia_lpdf_allocs,
        "mean Enzyme allocations"=>jdf.enzyme_allocs,
        "mean Mooncake allocations"=>jdf.mooncake_allocs,
        "constant lpdf difference"=>jdf.lpdf_difference,
        "remaining relative lpdf error"=>jdf.lpdf_accuracy,
        "Enzyme relative gradient error"=>jdf.enzyme_accuracy,
        "Mooncake relative gradient error"=>jdf.mooncake_accuracy, 
        "Enzyme"=>jdf.ENZYME_VERSION,
        "Mooncake"=>jdf.MOONCAKE_VERSION,
        "implementations"=>implementations_string.(jdf.posterior_name)
    ));
    backend=Val(:html), show_subheader=false, table_class="interactive"
)
```
:::